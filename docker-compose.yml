# =====================================================
# Platform: STREAMTEAM default
# =====================================================

#ALL
#docker-compose up --build --remove-orphans
#docker-compose down

#docker-compose start
#docker-compose stop

#Kafka
#docker exec -ti kafka-1 bash
#root@kafka-1:/# kafka-topics --create --if-not-exists --zookeeper zookeeper-1:2181 --topic test-topic --partitions 1 --replication-factor 1

#Simulator
#docker exec -it semesterarbeitcasbgd_simulator-1_1 bash
#root@simulator-1:/usr/src/app# cp ./data-transfer/simulator.py .
#root@simulator-1:/usr/src/app# python3 simulator.py

#kSQLDB-CLI
#to create the meta tables
#docker exec -it ksqldb-cli ksql http://ksqldb-server-1:8088
#RUN SCRIPT '/data-transfer/initKafkaTopics.sql'

#faust
#docker exec -it semesterarbeitcasbgd_faust-1_1 bash
#copy new version from data-transferto the app folder
#cp data-transfer/worker_fbRawGames.py .
#start faust worker
#faust -A worker_fbRawGames worker -l info --without-web
#send value to topic
#faust -A create_event send @greet -k '19060518.200' '{"ts": "2018-06-29T08:15:27.243860", "x": "-0.38", "y": "-2.23", "z": "0.0", "id": "200", "matchid": "19060518"}'
#faust -A create_event send @greet -k '19060518.10' '{"ts": "2018-06-29T08:15:27.243860", "x": "-0.39", "y": "-2.24", "z": "0.0", "id": "10", "matchid": "19060518"}'

version: '3'
# enforce some dependencies
services:
  #  ================================== Zookeeper ========================================== #}
  zookeeper-1:
    image: confluentinc/cp-zookeeper:5.5.0
    container_name: zookeeper-1
    hostname: zookeeper-1
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  # make sure that internal replication factor is not larger than the number of Kafka nodes
  #  ================================== Kafka-1 ========================================== #}
  kafka-1:
    image: confluentinc/cp-kafka:5.5.0
    container_name: kafka-1
    hostname: kafka-1
    depends_on:
      - zookeeper-1
    ports:
      - 9092:9092
      - 29092:29092
      - 9992:9992
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: r1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_LISTENERS: LISTENER_INTERNAL://kafka-1:19092,LISTENER_DOCKERHOST://kafka-1:29092,LISTENER_EXTERNAL://kafka-1:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka-1:19092,LISTENER_DOCKERHOST://localhost:29092,LISTENER_EXTERNAL://${PUBLIC_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_DOCKERHOST:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      #if we have more than one kafka node then the replication factor can be set to the # of kafka servers
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      #if we have more than one kafka node then the replication factor can be set to the # of kafka servers
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_DELETE_TOPIC_ENABLE: 'True'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'False'
      KAFKA_JMX_PORT: 9992
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9992
      KAFKA_JMX_HOSTNAME: kafka-1
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped  
  # #  ================================== Kafka-2 ========================================== #}
  # kafka-2:
  #   image: confluentinc/cp-kafka:5.5.0
  #   container_name: kafka-2
  #   hostname: kafka-2
  #   depends_on:
  #     - zookeeper-1
  #   ports:
  #     - 9093:9093
  #     - 29093:29093
  #     - 9993:9993
  #   environment:
  #     kafka_broker_id: 2
  #     kafka_broker_rack: r2
  #     kafka_zookeeper_connect: zookeeper-1:2181
  #     kafka_listeners: listener_internal://kafka-2:19093,listener_dockerhost://kafka-2:29093,listener_external://kafka-2:9093
  #     kafka_advertised_listeners: listener_internal://kafka-2:19093,listener_dockerhost://localhost:29093,listener_external://${public_ip:-127.0.0.1}:9093
  #     kafka_listener_security_protocol_map: listener_internal:plaintext,listener_dockerhost:plaintext,listener_external:plaintext
  #     kafka_inter_broker_listener_name: listener_internal
  #     #if we have more than one kafka node then the replication factor can be set to the # of kafka servers
  #     kafka_offsets_topic_replication_factor: 3
  #     kafka_transaction_state_log_min_isr: 1
  #     #if we have more than one kafka node then the replication factor can be set to the # of kafka servers
  #     kafka_transaction_state_log_replication_factor: 3
  #     kafka_group_initial_rebalance_delay_ms: 100
  #     kafka_delete_topic_enable: 'true'
  #     kafka_auto_create_topics_enable: 'false'
  #     kafka_jmx_port: 9993
  #     kafka_jmx_opts: -dcom.sun.management.jmxremote -dcom.sun.management.jmxremote.authenticate=false -dcom.sun.management.jmxremote.ssl=false -dcom.sun.management.jmxremote.local.only=false -dcom.sun.management.jmxremote.rmi.port=9993
  #     kafka_jmx_hostname: kafka-2
  #   volumes:
  #     - ./data-transfer:/data-transfer
  #   restart: unless-stopped
  # #  ================================== kafka-3 ========================================== #}
  # kafka-3:
  #   image: confluentinc/cp-kafka:5.5.0
  #   container_name: kafka-3
  #   hostname: kafka-3
  #   depends_on:
  #     - zookeeper-1
  #   ports:
  #     - 9094:9094
  #     - 29094:29094
  #     - 9994:9994
  #   environment:
  #     kafka_broker_id: 3
  #     kafka_broker_rack: r3
  #     kafka_zookeeper_connect: zookeeper-1:2181
  #     kafka_listeners: listener_internal://kafka-3:19094,listener_dockerhost://kafka-3:29094,listener_external://kafka-3:9094
  #     kafka_advertised_listeners: listener_internal://kafka-3:19094,listener_dockerhost://localhost:29094,listener_external://${public_ip:-127.0.0.1}:9094
  #     kafka_listener_security_protocol_map: listener_internal:plaintext,listener_dockerhost:plaintext,listener_external:plaintext
  #     kafka_inter_broker_listener_name: listener_internal
  #     #if we have more than one kafka node then the replication factor can be set to the # of kafka servers
  #     kafka_offsets_topic_replication_factor: 3
  #     kafka_transaction_state_log_min_isr: 1
  #     #if we have more than one kafka node then the replication factor can be set to the # of kafka servers
  #     kafka_transaction_state_log_replication_factor: 3
  #     kafka_group_initial_rebalance_delay_ms: 100
  #     kafka_delete_topic_enable: 'true'
  #     kafka_auto_create_topics_enable: 'false'
  #     kafka_jmx_port: 9994
  #     kafka_jmx_opts: -dcom.sun.management.jmxremote -dcom.sun.management.jmxremote.authenticate=false -dcom.sun.management.jmxremote.ssl=false -dcom.sun.management.jmxremote.local.only=false -dcom.sun.management.jmxremote.rmi.port=9994
  #     kafka_jmx_hostname: kafka-3
  #   volumes:
  #     - ./data-transfer:/data-transfer
  #   restart: unless-stopped
  #  ================================== Schema Registry ========================================== #}
  schema-registry-1:
    image: confluentinc/cp-schema-registry:5.5.0
    hostname: schema-registry-1
    container_name: schema-registry-1
    labels:
      com.mdps.service.restapi.url: http://${PUBLIC_IP}:8081
    depends_on:
      - zookeeper-1
      - kafka-1
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-1
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka-1:19092
      SCHEMA_REGISTRY_MASTER_ELIGIBILITY: 'true'
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: GET,POST,PUT,OPTIONS
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== Simulator ============================ #}
  simulator-1:
    build: 
      context: simulator
      dockerfile: Dockerfile
    #stdin_open: true
    hostname: simulator-1
    depends_on:
      - zookeeper-1
      - kafka-1
      - schema-registry-1
    environment:
      - KAFKA_BOOSTRAP_SERVER_NAME=kafka-1
      - KAFKA_BOOSTRAP_SERVER_PORT=9092
      - SCHEMA_REGISTRY_SERVER=schema-registry-1
      - SCHEMA_REGISTRY_SERVER_PORT=8081
    tty: true
    volumes:
      - ./simulator/data-transfer:/usr/src/app/data-transfer
#  ================================== faust ============================ #}
  faust-1:
    build:
      context: faust
      dockerfile: Dockerfile
    depends_on:
      - zookeeper-1
      - kafka-1
      - schema-registry-1
      - simulator-1
    environment:
      - WORKER=example
      - WORKER_PORT=6066
      - KAFKA_BOOTSTRAP_SERVER=kafka://kafka-1:9092
      - KAFKA_BOOSTRAP_SERVER_NAME=kafka-1
      - KAFKA_BOOSTRAP_SERVER_PORT=9092
      - SCHEMA_REGISTRY_URL=http://schema-registry-1:8081
      - SCHEMA_REGISTRY_SERVER=schema-registry-1
      - SCHEMA_REGISTRY_SERVER_PORT=8081
    ports:
      - "8084:80"
      - "8000:8000"
    tty: true
    volumes:
      - ./faust/data-transfer:/usr/src/app/data-transfer
#  ================================== Schema Registry UI ========================================== #}
  schema-registry-ui:
    image: landoop/schema-registry-ui:latest
    container_name: schema-registry-ui
    hostname: schema-registry-ui
    labels:
      com.mdps.service.webui.url: http://${PUBLIC_IP}:28102
    depends_on:
      - kafka-1
      - schema-registry-1
    ports:
      - 28102:8000
    environment:
      SCHEMAREGISTRY_URL: http://${PUBLIC_IP}:8081
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
#  ================================== Kafkacat  ========================================== #}
  kafkacat:
    image: edenhill/kafkacat:1.5.0
    container_name: kafkacat
    hostname: kafkacat
    volumes:
      - ./data-transfer:/data-transfer
    entrypoint:
      - /bin/sh
      - -c
      - |
        apk add jq;
        while [ 1 -eq 1 ];do sleep 60;done
    restart: unless-stopped
  #  ================================== Apache Kafka HQ (AKHQ) ========================================== #}
  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    hostname: akhq
    labels:
      com.mdps.service.webui.url: http://${PUBLIC_IP}:28107
    ports:
      - 28107:8080
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka-1:19092"
              schema-registry:
                url: "http://schema-registry-1:8081"
              connect:
                url: "http://kafka-connect-1:8083"
    depends_on:
      - kafka-1
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped

  #  ================================== ksqlDB ========================================== #}
  ksqldb-server-1:
    image: confluentinc/ksqldb-server:0.9.0
    hostname: ksqldb-server-1
    container_name: ksqldb-server-1
    labels:
      com.mdps.service.restapi.url: http://${PUBLIC_IP}:8088
    ports:
      - 8088:8088
    depends_on:
      - kafka-1
      - schema-registry-1
    environment:
      KSQL_CONFIG_DIR: /etc/ksql
      KSQL_LOG4J_OPTS: -Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties
      KSQL_BOOTSTRAP_SERVERS: kafka-1:19092
      KSQL_HOST_NAME: ksqldb-server-1
      KSQL_APPLICATION_ID: kafka-demo
      #is this 0.0.0.0 correct?
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry-1:8081
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_SERVICE_ID: kafka-demo
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/ksql:/etc/ksql/ext
    restart: unless-stopped
  #  ================================== ksql cli ========================================== #}
  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.9.0
    container_name: ksqldb-cli
    hostname: ksqldb-cli
    depends_on:
      - ksqldb-server-1
    volumes:
      - ./data-transfer:/data-transfer
    entrypoint: /bin/sh
    tty: true